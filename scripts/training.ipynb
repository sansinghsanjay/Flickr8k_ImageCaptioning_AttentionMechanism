{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 2366,
     "status": "ok",
     "timestamp": 1621328091114,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "CgKbbYxJ5t8q",
    "outputId": "54c1fdfe-85a5-4499-fc95-d7512029261a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSanjay Singh\\nsan.singhsanjay@gmail.com\\nApril-2021\\nImplementation of Attention Mechanism for Image Captioning - Most part taken from Google Tutorials\\nImplementation of:\\nhttps://github.com/subhamio/image-captioning-using-attention-mechanism-local-attention-and-global-attention-/blob/master/image_captioning_using_attention_mechanism.ipynb\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Sanjay Singh\n",
    "san.singhsanjay@gmail.com\n",
    "April-2021\n",
    "Implementation of Attention Mechanism for Image Captioning - Most part taken from Google Tutorials\n",
    "Implementation of:\n",
    "https://github.com/subhamio/image-captioning-using-attention-mechanism-local-attention-and-global-attention-/blob/master/image_captioning_using_attention_mechanism.ipynb\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4981,
     "status": "ok",
     "timestamp": 1621328093783,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "ZTKEHdjOASw6"
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "import tensorflow as tf\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from numpy import array\n",
    "from pickle import load\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "import keras\n",
    "import sys, time, os, warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.utils import shuffle\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4996,
     "status": "ok",
     "timestamp": 1621328093816,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "PvEwL-9BHA0W"
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "EMBEDDING_DIM = 256\n",
    "BATCH_SIZE = 131\n",
    "BUFFER_SIZE = 1000\n",
    "UNITS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4983,
     "status": "ok",
     "timestamp": 1621328093819,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "55Tl9qX9IQb4"
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "images_path = \"/notebooks/train_npy_files/\"\n",
    "img_captions_csv_path = \"/notebooks/output/intermediate_files/train_image_caption_processed.csv\"\n",
    "vocabulary_path = \"/notebooks/output/intermediate_files/vocabulary.txt\"\n",
    "max_caption_len_path = \"/notebooks/output/intermediate_files/max_caption_length.txt\"\n",
    "checkpoint_path = \"/notebooks/output/attention_mech_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4969,
     "status": "ok",
     "timestamp": 1621328093822,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "nmqIz8RCH15E"
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/text/image_captioning\n",
    "class VGG16_Encoder(tf.keras.Model):\n",
    "\t# This encoder passes the features through a Fully connected layer\n",
    "\tdef __init__(self, EMBEDDING_DIM):\n",
    "\t\tsuper(VGG16_Encoder, self).__init__()\n",
    "\t\tself.fc = tf.keras.layers.Dense(EMBEDDING_DIM)\n",
    "\t\tself.dropout = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)\n",
    "\tdef call(self, x):\n",
    "\t\tx = self.fc(x)\n",
    "\t\tx = tf.nn.relu(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4955,
     "status": "ok",
     "timestamp": 1621328093824,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "9SAhYeGOH7vv"
   },
   "outputs": [],
   "source": [
    "class Rnn_Local_Decoder(tf.keras.Model):\n",
    "\tdef __init__(self, embedding_dim, UNITS, vocab_size):\n",
    "\t\tsuper(Rnn_Local_Decoder, self).__init__()\n",
    "\t\tself.units = UNITS\n",
    "\t\tself.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\t\tself.gru = tf.compat.v1.keras.layers.CuDNNGRU(self.units, return_sequences=True, return_state=True,                              recurrent_initializer='glorot_uniform')\n",
    "\t\tself.fc1 = tf.keras.layers.Dense(self.units)\n",
    "\t\tself.dropout = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)\n",
    "\t\tself.batchnormalization = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\t\tself.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\t\t# Implementing Attention Mechanism\n",
    "\t\tself.Uattn = tf.keras.layers.Dense(UNITS)\n",
    "\t\tself.Wattn = tf.keras.layers.Dense(UNITS)\n",
    "\t\tself.Vattn = tf.keras.layers.Dense(1)\n",
    "\n",
    "\tdef call(self, x, features, hidden):\n",
    "\t\t# features shape ==> (64,49,256) ==> Output from ENCODER\n",
    "\t\t# hidden shape == (batch_size, hidden_size) ==>(64,512)\n",
    "\t\t# hidden_with_time_axis shape == (batch_size, 1, hidden_size) ==> (64,1,512)\n",
    "\t\thidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\t\t# score shape == (64, 49, 1)\n",
    "\t\t# Attention Function\n",
    "\t\t'''e(ij) = f(s(t-1),h(j))'''\n",
    "\t\t''' e(ij) = Vattn(T)*tanh(Uattn * h(j) + Wattn * s(t))'''\n",
    "\t\tscore = self.Vattn(tf.nn.tanh(self.Uattn(features) + self.Wattn(hidden_with_time_axis)))\n",
    "\t\t# self.Uattn(features) : (64,49,512)\n",
    "\t\t# self.Wattn(hidden_with_time_axis) : (64,1,512)\n",
    "\t\t# tf.nn.tanh(self.Uattn(features) + self.Wattn(hidden_with_time_axis)) : (64,49,512)\n",
    "\t\t# self.Vattn(tf.nn.tanh(self.Uattn(features) + self.Wattn(hidden_with_time_axis))) : (64,49,1) ==> score\n",
    "\t\t# you get 1 at the last axis because you are applying score to self.Vattn\n",
    "\t\t# Then find Probability using Softmax\n",
    "\t\t'''attention_weights(alpha(ij)) = softmax(e(ij))'''\n",
    "\t\tattention_weights = tf.nn.softmax(score, axis=1)\n",
    "\t\t# attention_weights shape == (64, 49, 1)\n",
    "\t\t# Give weights to the different pixels in the image\n",
    "\t\t''' C(t) = Summation(j=1 to T) (attention_weights * VGG-16 features) '''\n",
    "\t\tcontext_vector = attention_weights * features\n",
    "\t\tcontext_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\t\t# Context Vector(64,256) = AttentionWeights(64,49,1) * features(64,49,256)\n",
    "\t\t# context_vector shape after sum == (64, 256)\n",
    "\t\t# x shape after passing through embedding == (64, 1, 256)\n",
    "\t\tx = self.embedding(x)\n",
    "\t\t# x shape after concatenation == (64, 1,  512)\n",
    "\t\tx = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\t\t# passing the concatenated vector to the GRU\n",
    "\t\toutput, state = self.gru(x)\n",
    "\t\t# shape == (batch_size, max_length, hidden_size)\n",
    "\t\tx = self.fc1(output)\n",
    "\t\t# x shape == (batch_size * max_length, hidden_size)\n",
    "\t\tx = tf.reshape(x, (-1, x.shape[2]))\n",
    "\t\t# Adding Dropout and BatchNorm Layers\n",
    "\t\tx= self.dropout(x)\n",
    "\t\tx= self.batchnormalization(x)\n",
    "\t\t# output shape == (64 * 512)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\t# shape : (64 * 8329(vocab))\n",
    "\t\treturn x, state, attention_weights\n",
    "\n",
    "\tdef reset_state(self, batch_size):\n",
    "\t\treturn tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4943,
     "status": "ok",
     "timestamp": 1621328093827,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "0B9aUr_2IAYV"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "\tmask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "\tloss_ = loss_object(real, pred)\n",
    "\tmask = tf.cast(mask, dtype=loss_.dtype)\n",
    "\tloss_ *= mask\n",
    "\treturn tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4930,
     "status": "ok",
     "timestamp": 1621328093830,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "LY8XNty0IETK"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img_tensor, target):\n",
    "\tloss = 0\n",
    "\t# initializing the hidden state for each batch\n",
    "\t# because the captions are not related from image to image\n",
    "\thidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "\tdec_input = tf.expand_dims([wordtoix['startseq']] * BATCH_SIZE, 1)\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\tfeatures = encoder(img_tensor)\n",
    "\t\tfor i in range(1, target.shape[1]):\n",
    "\t\t\t# passing the features through the decoder\n",
    "\t\t\tpredictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "\t\t\tloss += loss_function(target[:, i], predictions)\n",
    "\t\t\t# using teacher forcing\n",
    "\t\t\tdec_input = tf.expand_dims(target[:, i], 1)\n",
    "\ttotal_loss = (loss / int(target.shape[1]))\n",
    "\ttrainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\tgradients = tape.gradient(loss, trainable_variables)\n",
    "\toptimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\treturn loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4919,
     "status": "ok",
     "timestamp": 1621328093834,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "13LIAyZuIIt1"
   },
   "outputs": [],
   "source": [
    "# function to read, resize and preprocess an image\n",
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = preprocess_input(img)\n",
    "    return img, image_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4907,
     "status": "ok",
     "timestamp": 1621328093837,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "CEgBBBu7INJM"
   },
   "outputs": [],
   "source": [
    "def map_func(img_name, cap):\n",
    "\timg_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
    "\treturn img_tensor, cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4895,
     "status": "ok",
     "timestamp": 1621328093839,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "nmTtV8YMIUQb"
   },
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "data = pd.read_csv(img_captions_csv_path)\n",
    "img_name = list(data['image'])\n",
    "img_caption = list(data['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4884,
     "status": "ok",
     "timestamp": 1621328093841,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "hBsiooRXIZNo"
   },
   "outputs": [],
   "source": [
    "# appending image names to their paths\n",
    "for i in range(len(img_name)):\n",
    "\timg_name[i] = images_path + img_name[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4876,
     "status": "ok",
     "timestamp": 1621328093845,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "bOjBkjNMIc_q"
   },
   "outputs": [],
   "source": [
    "# reading vocabulary file\n",
    "vocabulary = list()\n",
    "f_ptr = open(vocabulary_path, \"r\")\n",
    "lines = f_ptr.readlines()\n",
    "for line in lines:\n",
    "\tvocabulary.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4864,
     "status": "ok",
     "timestamp": 1621328093847,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "0q2-rZk_IuMg",
    "outputId": "fb97cc64-64fe-4557-98b2-13ff2e76ed3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  1657\n"
     ]
    }
   ],
   "source": [
    "# finding size of vocabulary\n",
    "vocab_size = len(vocabulary) + 1 # added 1 for padded zero\n",
    "print(\"Vocabulary Size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4849,
     "status": "ok",
     "timestamp": 1621328093851,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "5-krs1w8Ixx8"
   },
   "outputs": [],
   "source": [
    "# making word-to-index and index-to-word dictionary\n",
    "wordtoix = dict()\n",
    "ixtoword = dict()\n",
    "for i in range(len(vocabulary)):\n",
    "\twordtoix[vocabulary[i]] = (i + 1)\n",
    "\tixtoword[(i + 1)] = vocabulary[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4835,
     "status": "ok",
     "timestamp": 1621328093854,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "9sQsht1PI2Rf",
    "outputId": "ca28d9b9-178c-4147-a180-a1904b969d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Caption Length:  31\n"
     ]
    }
   ],
   "source": [
    "# finding max caption length\n",
    "f_ptr = open(max_caption_len_path, 'r')\n",
    "data = f_ptr.read()\n",
    "f_ptr.close()\n",
    "max_caption_len = int(data.split(\":\")[1].strip())\n",
    "print(\"Max Caption Length: \", max_caption_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4820,
     "status": "ok",
     "timestamp": 1621328093857,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "xsDqz0oaI529",
    "outputId": "1796904a-e256-41af-cdeb-775fe36750d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all_img_names:  29999\n",
      "Length of all_captions:  29999\n"
     ]
    }
   ],
   "source": [
    "# converting captions to their indices\n",
    "all_img_names = list()\n",
    "all_captions = list()\n",
    "img_caption_ix = list()\n",
    "for i in range(len(img_caption)):\n",
    "\tcaptions = img_caption[i].split(\"#\")\n",
    "\tfor caption in captions:\n",
    "\t\tall_img_names.append(img_name[i])\n",
    "\t\tall_captions.append(caption)\n",
    "\t\twords = caption.split(\" \")\n",
    "\t\ttemp_list = list()\n",
    "\t\tfor word in words:\n",
    "\t\t\tif(word in wordtoix):\n",
    "\t\t\t\ttemp_list.append(wordtoix[word])\n",
    "\t\timg_caption_ix.append(temp_list)\n",
    "# printing shape of all_img_names and all_captions\n",
    "print(\"Length of all_img_names: \", len(all_img_names))\n",
    "print(\"Length of all_captions: \", len(all_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5888,
     "status": "ok",
     "timestamp": 1621328094944,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "2P2tGjIUI9VL",
    "outputId": "599f4d8e-f42a-483c-f88e-3a0044da05d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of img_caption_padded:  (29999, 31)\n"
     ]
    }
   ],
   "source": [
    "# padding zeros to each caption to make it equal to max_caption_len\n",
    "img_caption_padded = tf.keras.preprocessing.sequence.pad_sequences(img_caption_ix, max_caption_len, padding='post')\n",
    "print(\"Shape of img_caption_padded: \", img_caption_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 5874,
     "status": "ok",
     "timestamp": 1621328094948,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "350YZjqJJEZW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# loading vgg-16 model to extract bottleneck features\n",
    "image_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet')\n",
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 5857,
     "status": "ok",
     "timestamp": 1621328094952,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "n91KTNQ9JHrE",
    "outputId": "d8d82eae-b626-413b-f119-4a8c43e2ab6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# to map data to loading function - to create npy files\\nencode_train = sorted(set(img_name))\\nimage_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\\nimage_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\\n\\n# saving npy files\\nfor img, path in tqdm(image_dataset):\\n\\tbatch_features = image_features_extract_model(img) # batch_features.shape: [BATCH_SIZE, 7, 7, 512]\\n\\tbatch_features = tf.reshape(batch_features, (batch_features.shape[0], -1, batch_features.shape[3])) # batch_features.shape: [BATCH_SIZE, 49, 512]\\n\\tfor bf, p in zip(batch_features, path):\\n\\t\\tpath_of_feature = p.numpy().decode(\"utf-8\")\\n\\t\\tnp.save(path_of_feature, bf.numpy())\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# to map data to loading function - to create npy files\n",
    "encode_train = sorted(set(img_name))\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
    "image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\n",
    "\n",
    "# saving npy files\n",
    "for img, path in tqdm(image_dataset):\n",
    "\tbatch_features = image_features_extract_model(img) # batch_features.shape: [BATCH_SIZE, 7, 7, 512]\n",
    "\tbatch_features = tf.reshape(batch_features, (batch_features.shape[0], -1, batch_features.shape[3])) # batch_features.shape: [BATCH_SIZE, 49, 512]\n",
    "\tfor bf, p in zip(batch_features, path):\n",
    "\t\tpath_of_feature = p.numpy().decode(\"utf-8\")\n",
    "\t\tnp.save(path_of_feature, bf.numpy())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 5842,
     "status": "ok",
     "timestamp": 1621328094956,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "AJfbd79iJLoo"
   },
   "outputs": [],
   "source": [
    "# defining optimization and loss-object\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 6555,
     "status": "ok",
     "timestamp": 1621328095681,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "0t95e67JJoXX"
   },
   "outputs": [],
   "source": [
    "# making image and caption map - for training\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_img_names, img_caption_padded))\n",
    "dataset = dataset.map(lambda item1, item2: tf.numpy_function(map_func, [item1, item2], [tf.float32, tf.int32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "#dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 6547,
     "status": "ok",
     "timestamp": 1621328095686,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "axHZcVYDJq3G"
   },
   "outputs": [],
   "source": [
    "# defining encoder and decoder\n",
    "encoder = VGG16_Encoder(EMBEDDING_DIM)\n",
    "decoder = Rnn_Local_Decoder(EMBEDDING_DIM, UNITS, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6535,
     "status": "ok",
     "timestamp": 1621328095688,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "j0pz6tAbJumO",
    "outputId": "c11cc0fc-0847-4fc4-b9a0-ffdfc9b0518d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_steps:  229\n"
     ]
    }
   ],
   "source": [
    "# defining num_steps \n",
    "num_steps = len(all_img_names) // BATCH_SIZE\n",
    "print(\"num_steps: \", num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 1570384,
     "status": "error",
     "timestamp": 1621329659557,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "4dl4ozmGJxGH",
    "outputId": "74254dee-f7d8-4910-fc92-82601bf3ea6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for epoch-1 and batch-1: 31.078460454940796 sec, Loss: 2.355736517137097\n",
      "\n",
      "Time taken for epoch-1 and batch-101: 47.56829500198364 sec, Loss: 1.4008643857894405\n",
      "\n",
      "Time taken for epoch-1 and batch-201: 63.765931129455566 sec, Loss: 1.2464421179986769\n",
      "\n",
      "Epoch 1 Loss 1.435031\n",
      "Time taken for 1 epoch 68.2715675830841 sec\n",
      "\n",
      "Time taken for epoch-2 and batch-1: 0.9605855941772461 sec, Loss: 1.2766679333102318\n",
      "\n",
      "Time taken for epoch-2 and batch-101: 17.07727861404419 sec, Loss: 1.1391805833385837\n",
      "\n",
      "Time taken for epoch-2 and batch-201: 33.20539617538452 sec, Loss: 1.1253345858666204\n",
      "\n",
      "Epoch 2 Loss 1.124673\n",
      "Time taken for 1 epoch 37.6733512878418 sec\n",
      "\n",
      "Time taken for epoch-3 and batch-1: 0.9552140235900879 sec, Loss: 1.107698009860131\n",
      "\n",
      "Time taken for epoch-3 and batch-101: 17.094136953353882 sec, Loss: 1.1142519058719758\n",
      "\n",
      "Time taken for epoch-3 and batch-201: 33.198134660720825 sec, Loss: 0.9457636187153478\n",
      "\n",
      "Epoch 3 Loss 1.016173\n",
      "Time taken for 1 epoch 37.69466996192932 sec\n",
      "\n",
      "Time taken for epoch-4 and batch-1: 0.9451379776000977 sec, Loss: 0.9786885169244581\n",
      "\n",
      "Time taken for epoch-4 and batch-101: 17.011346101760864 sec, Loss: 0.9400047794465096\n",
      "\n",
      "Time taken for epoch-4 and batch-201: 33.1195502281189 sec, Loss: 0.8863313736454133\n",
      "\n",
      "Epoch 4 Loss 0.944583\n",
      "Time taken for 1 epoch 37.63034105300903 sec\n",
      "\n",
      "Time taken for epoch-5 and batch-1: 0.9295988082885742 sec, Loss: 0.9544998907273815\n",
      "\n",
      "Time taken for epoch-5 and batch-101: 17.02768063545227 sec, Loss: 0.9311990430278163\n",
      "\n",
      "Time taken for epoch-5 and batch-201: 33.19556188583374 sec, Loss: 0.9191830542779738\n",
      "\n",
      "Epoch 5 Loss 0.888443\n",
      "Time taken for 1 epoch 37.735833168029785 sec\n",
      "\n",
      "Time taken for epoch-6 and batch-1: 0.9439864158630371 sec, Loss: 0.8365191182782573\n",
      "\n",
      "Time taken for epoch-6 and batch-101: 17.095117568969727 sec, Loss: 0.8502348007694367\n",
      "\n",
      "Time taken for epoch-6 and batch-201: 33.24945569038391 sec, Loss: 0.8454903633363785\n",
      "\n",
      "Epoch 6 Loss 0.841662\n",
      "Time taken for 1 epoch 37.79332184791565 sec\n",
      "\n",
      "Time taken for epoch-7 and batch-1: 0.9661571979522705 sec, Loss: 0.8328732521303238\n",
      "\n",
      "Time taken for epoch-7 and batch-101: 17.085001945495605 sec, Loss: 0.8499069213867188\n",
      "\n",
      "Time taken for epoch-7 and batch-201: 33.27098894119263 sec, Loss: 0.7615294917937248\n",
      "\n",
      "Epoch 7 Loss 0.800323\n",
      "Time taken for 1 epoch 37.77885317802429 sec\n",
      "\n",
      "Time taken for epoch-8 and batch-1: 0.973721981048584 sec, Loss: 0.773375234296245\n",
      "\n",
      "Time taken for epoch-8 and batch-101: 17.131672859191895 sec, Loss: 0.7810635720529864\n",
      "\n",
      "Time taken for epoch-8 and batch-201: 33.26258087158203 sec, Loss: 0.8224610359438004\n",
      "\n",
      "Epoch 8 Loss 0.763535\n",
      "Time taken for 1 epoch 37.745654582977295 sec\n",
      "\n",
      "Time taken for epoch-9 and batch-1: 0.9443867206573486 sec, Loss: 0.7872347677907636\n",
      "\n",
      "Time taken for epoch-9 and batch-101: 17.100956439971924 sec, Loss: 0.7741031646728516\n",
      "\n",
      "Time taken for epoch-9 and batch-201: 33.23194360733032 sec, Loss: 0.7024435227917086\n",
      "\n",
      "Epoch 9 Loss 0.728485\n",
      "Time taken for 1 epoch 37.754823207855225 sec\n",
      "\n",
      "Time taken for epoch-10 and batch-1: 0.9496657848358154 sec, Loss: 0.7585408610682334\n",
      "\n",
      "Time taken for epoch-10 and batch-101: 17.146565675735474 sec, Loss: 0.714263177687122\n",
      "\n",
      "Time taken for epoch-10 and batch-201: 33.32553458213806 sec, Loss: 0.6913676723357169\n",
      "\n",
      "Epoch 10 Loss 0.697573\n",
      "Time taken for 1 epoch 37.827847719192505 sec\n",
      "\n",
      "Time taken for epoch-11 and batch-1: 0.9558775424957275 sec, Loss: 0.7587318420410156\n",
      "\n",
      "Time taken for epoch-11 and batch-101: 17.124688148498535 sec, Loss: 0.7022297766900831\n",
      "\n",
      "Time taken for epoch-11 and batch-201: 33.34624695777893 sec, Loss: 0.6284991848853326\n",
      "\n",
      "Epoch 11 Loss 0.667427\n",
      "Time taken for 1 epoch 37.844287395477295 sec\n",
      "\n",
      "Time taken for epoch-12 and batch-1: 0.9434614181518555 sec, Loss: 0.679260500015751\n",
      "\n",
      "Time taken for epoch-12 and batch-101: 17.06006669998169 sec, Loss: 0.6476138945548765\n",
      "\n",
      "Time taken for epoch-12 and batch-201: 33.24445676803589 sec, Loss: 0.676559817406439\n",
      "\n",
      "Epoch 12 Loss 0.640969\n",
      "Time taken for 1 epoch 37.738667011260986 sec\n",
      "\n",
      "Time taken for epoch-13 and batch-1: 0.9248261451721191 sec, Loss: 0.581788093813004\n",
      "\n",
      "Time taken for epoch-13 and batch-101: 17.13673210144043 sec, Loss: 0.6088485717773438\n",
      "\n",
      "Time taken for epoch-13 and batch-201: 33.278135538101196 sec, Loss: 0.6045086768365675\n",
      "\n",
      "Epoch 13 Loss 0.614488\n",
      "Time taken for 1 epoch 37.79282307624817 sec\n",
      "\n",
      "Time taken for epoch-14 and batch-1: 0.9259898662567139 sec, Loss: 0.5826222819666709\n",
      "\n",
      "Time taken for epoch-14 and batch-101: 17.100318908691406 sec, Loss: 0.613981431530368\n",
      "\n",
      "Time taken for epoch-14 and batch-201: 33.220102310180664 sec, Loss: 0.604903067311933\n",
      "\n",
      "Epoch 14 Loss 0.590199\n",
      "Time taken for 1 epoch 37.723628282547 sec\n",
      "\n",
      "Time taken for epoch-15 and batch-1: 0.9357926845550537 sec, Loss: 0.5858904930853075\n",
      "\n",
      "Time taken for epoch-15 and batch-101: 17.01074481010437 sec, Loss: 0.5535700398106729\n",
      "\n",
      "Time taken for epoch-15 and batch-201: 33.16198801994324 sec, Loss: 0.5428969475530809\n",
      "\n",
      "Epoch 15 Loss 0.567917\n",
      "Time taken for 1 epoch 37.67528247833252 sec\n",
      "\n",
      "Time taken for epoch-16 and batch-1: 0.9837276935577393 sec, Loss: 0.566802240187122\n",
      "\n",
      "Time taken for epoch-16 and batch-101: 17.076229095458984 sec, Loss: 0.5516265746085874\n",
      "\n",
      "Time taken for epoch-16 and batch-201: 33.27600312232971 sec, Loss: 0.5538554037770917\n",
      "\n",
      "Epoch 16 Loss 0.546358\n",
      "Time taken for 1 epoch 37.80031609535217 sec\n",
      "\n",
      "Time taken for epoch-17 and batch-1: 0.9695003032684326 sec, Loss: 0.5559280149398311\n",
      "\n",
      "Time taken for epoch-17 and batch-101: 17.129809856414795 sec, Loss: 0.5145280284266318\n",
      "\n",
      "Time taken for epoch-17 and batch-201: 33.37231183052063 sec, Loss: 0.4902251458937122\n",
      "\n",
      "Epoch 17 Loss 0.526574\n",
      "Time taken for 1 epoch 37.886369705200195 sec\n",
      "\n",
      "Time taken for epoch-18 and batch-1: 0.9457745552062988 sec, Loss: 0.5251309794764365\n",
      "\n",
      "Time taken for epoch-18 and batch-101: 17.128796339035034 sec, Loss: 0.553634766609438\n",
      "\n",
      "Time taken for epoch-18 and batch-201: 33.33872985839844 sec, Loss: 0.523743906328755\n",
      "\n",
      "Epoch 18 Loss 0.506688\n",
      "Time taken for 1 epoch 37.8546187877655 sec\n",
      "\n",
      "Time taken for epoch-19 and batch-1: 0.943713903427124 sec, Loss: 0.4918401779667024\n",
      "\n",
      "Time taken for epoch-19 and batch-101: 17.1317937374115 sec, Loss: 0.4503344258954448\n",
      "\n",
      "Time taken for epoch-19 and batch-201: 33.33121681213379 sec, Loss: 0.5318033156856414\n",
      "\n",
      "Epoch 19 Loss 0.488203\n",
      "Time taken for 1 epoch 37.8690824508667 sec\n",
      "\n",
      "Time taken for epoch-20 and batch-1: 0.9381482601165771 sec, Loss: 0.5207476462087324\n",
      "\n",
      "Time taken for epoch-20 and batch-101: 17.16871404647827 sec, Loss: 0.4560661315917969\n",
      "\n",
      "Time taken for epoch-20 and batch-201: 33.35562562942505 sec, Loss: 0.4608954152753276\n",
      "\n",
      "Epoch 20 Loss 0.473071\n",
      "Time taken for 1 epoch 37.88423752784729 sec\n",
      "\n",
      "Time taken for epoch-21 and batch-1: 0.9836111068725586 sec, Loss: 0.47522095711000506\n",
      "\n",
      "Time taken for epoch-21 and batch-101: 17.27552103996277 sec, Loss: 0.47656339214694116\n",
      "\n",
      "Time taken for epoch-21 and batch-201: 33.56514525413513 sec, Loss: 0.4839890695387317\n",
      "\n",
      "Epoch 21 Loss 0.456410\n",
      "Time taken for 1 epoch 38.11489534378052 sec\n",
      "\n",
      "Time taken for epoch-22 and batch-1: 1.022207260131836 sec, Loss: 0.48217585779005484\n",
      "\n",
      "Time taken for epoch-22 and batch-101: 17.240605115890503 sec, Loss: 0.45577987547843685\n",
      "\n",
      "Time taken for epoch-22 and batch-201: 33.46947431564331 sec, Loss: 0.4414020661384829\n",
      "\n",
      "Epoch 22 Loss 0.442295\n",
      "Time taken for 1 epoch 37.997360706329346 sec\n",
      "\n",
      "Time taken for epoch-23 and batch-1: 0.9428894519805908 sec, Loss: 0.4347801823769846\n",
      "\n",
      "Time taken for epoch-23 and batch-101: 17.117961883544922 sec, Loss: 0.4408371217789189\n",
      "\n",
      "Time taken for epoch-23 and batch-201: 33.31589102745056 sec, Loss: 0.42186558631158644\n",
      "\n",
      "Epoch 23 Loss 0.427784\n",
      "Time taken for 1 epoch 37.822460651397705 sec\n",
      "\n",
      "Time taken for epoch-24 and batch-1: 0.9713947772979736 sec, Loss: 0.43594458795362906\n",
      "\n",
      "Time taken for epoch-24 and batch-101: 17.2100567817688 sec, Loss: 0.42035650437878025\n",
      "\n",
      "Time taken for epoch-24 and batch-201: 33.418540954589844 sec, Loss: 0.41995220799599925\n",
      "\n",
      "Epoch 24 Loss 0.415264\n",
      "Time taken for 1 epoch 37.94272208213806 sec\n",
      "\n",
      "Time taken for epoch-25 and batch-1: 0.9616127014160156 sec, Loss: 0.39029502868652344\n",
      "\n",
      "Time taken for epoch-25 and batch-101: 17.22052001953125 sec, Loss: 0.4124106130292339\n",
      "\n",
      "Time taken for epoch-25 and batch-201: 33.455352783203125 sec, Loss: 0.4297546878937752\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss 0.403093\n",
      "Time taken for 1 epoch 37.98216390609741 sec\n",
      "\n",
      "Time taken for epoch-26 and batch-1: 0.9775323867797852 sec, Loss: 0.39856769192603325\n",
      "\n",
      "Time taken for epoch-26 and batch-101: 17.219427585601807 sec, Loss: 0.41864739694902975\n",
      "\n",
      "Time taken for epoch-26 and batch-201: 33.48539638519287 sec, Loss: 0.4055219465686429\n",
      "\n",
      "Epoch 26 Loss 0.392747\n",
      "Time taken for 1 epoch 37.999157428741455 sec\n",
      "\n",
      "Time taken for epoch-27 and batch-1: 0.9653928279876709 sec, Loss: 0.400848880890877\n",
      "\n",
      "Time taken for epoch-27 and batch-101: 17.155367374420166 sec, Loss: 0.3757852738903415\n",
      "\n",
      "Time taken for epoch-27 and batch-201: 33.311015367507935 sec, Loss: 0.3854927555207283\n",
      "\n",
      "Epoch 27 Loss 0.380980\n",
      "Time taken for 1 epoch 37.85389256477356 sec\n",
      "\n",
      "Time taken for epoch-28 and batch-1: 1.0084285736083984 sec, Loss: 0.3446708186980217\n",
      "\n",
      "Time taken for epoch-28 and batch-101: 17.207897186279297 sec, Loss: 0.37770818894909275\n",
      "\n",
      "Time taken for epoch-28 and batch-201: 33.49360132217407 sec, Loss: 0.37000357720159716\n",
      "\n",
      "Epoch 28 Loss 0.370622\n",
      "Time taken for 1 epoch 38.02790188789368 sec\n",
      "\n",
      "Time taken for epoch-29 and batch-1: 0.9918520450592041 sec, Loss: 0.3620950022051411\n",
      "\n",
      "Time taken for epoch-29 and batch-101: 17.218523025512695 sec, Loss: 0.3680996433381111\n",
      "\n",
      "Time taken for epoch-29 and batch-201: 33.41124892234802 sec, Loss: 0.3566358627811555\n",
      "\n",
      "Epoch 29 Loss 0.360826\n",
      "Time taken for 1 epoch 37.98068404197693 sec\n",
      "\n",
      "Time taken for epoch-30 and batch-1: 0.9871816635131836 sec, Loss: 0.34867360514979207\n",
      "\n",
      "Time taken for epoch-30 and batch-101: 17.17803382873535 sec, Loss: 0.3560142209452967\n",
      "\n",
      "Time taken for epoch-30 and batch-201: 33.37343406677246 sec, Loss: 0.3516215047528667\n",
      "\n",
      "Epoch 30 Loss 0.352268\n",
      "Time taken for 1 epoch 37.937973737716675 sec\n",
      "\n",
      "Time taken for epoch-31 and batch-1: 0.9845716953277588 sec, Loss: 0.3360266531667402\n",
      "\n",
      "Time taken for epoch-31 and batch-101: 17.226539611816406 sec, Loss: 0.3508177726499496\n",
      "\n",
      "Time taken for epoch-31 and batch-201: 33.47861647605896 sec, Loss: 0.34590072016562184\n",
      "\n",
      "Epoch 31 Loss 0.343606\n",
      "Time taken for 1 epoch 38.000425577163696 sec\n",
      "\n",
      "Time taken for epoch-32 and batch-1: 0.9639310836791992 sec, Loss: 0.34183311462402344\n",
      "\n",
      "Time taken for epoch-32 and batch-101: 17.235878467559814 sec, Loss: 0.33204856995613347\n",
      "\n",
      "Time taken for epoch-32 and batch-201: 33.410284996032715 sec, Loss: 0.3430422198387884\n",
      "\n",
      "Epoch 32 Loss 0.335440\n",
      "Time taken for 1 epoch 37.94438171386719 sec\n",
      "\n",
      "Time taken for epoch-33 and batch-1: 0.9446275234222412 sec, Loss: 0.3436182391258978\n",
      "\n",
      "Time taken for epoch-33 and batch-101: 17.15823197364807 sec, Loss: 0.34503084613430884\n",
      "\n",
      "Time taken for epoch-33 and batch-201: 33.39463424682617 sec, Loss: 0.33776043307396675\n",
      "\n",
      "Epoch 33 Loss 0.328242\n",
      "Time taken for 1 epoch 37.909032344818115 sec\n",
      "\n",
      "Time taken for epoch-34 and batch-1: 1.009652853012085 sec, Loss: 0.3080201918079007\n",
      "\n",
      "Time taken for epoch-34 and batch-101: 17.23249626159668 sec, Loss: 0.3304322150445754\n",
      "\n",
      "Time taken for epoch-34 and batch-201: 33.396997928619385 sec, Loss: 0.3230395778532951\n",
      "\n",
      "Epoch 34 Loss 0.320720\n",
      "Time taken for 1 epoch 37.94571590423584 sec\n",
      "\n",
      "Time taken for epoch-35 and batch-1: 0.9439713954925537 sec, Loss: 0.3135093258273217\n",
      "\n",
      "Time taken for epoch-35 and batch-101: 17.14785599708557 sec, Loss: 0.31773985585858744\n",
      "\n",
      "Time taken for epoch-35 and batch-201: 33.38790225982666 sec, Loss: 0.32329100947226247\n",
      "\n",
      "Epoch 35 Loss 0.314269\n",
      "Time taken for 1 epoch 37.91736960411072 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training related parameters and training\n",
    "loss_plot = []\n",
    "start_epoch = 0\n",
    "EPOCHS = 35\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "        #target = tf.reshape(target, (1, target.shape[0]))\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "        if batch % 100 == 0:\n",
    "            print(\"Time taken for epoch-{} and batch-{}: {} sec, Loss: {}\\n\".format(epoch + 1, batch + 1, time.time() - start, batch_loss.numpy() / int(target.shape[1])))\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1, total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1570355,
     "status": "aborted",
     "timestamp": 1621329659546,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "AKuLFXhhtG1X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks/output/attention_mech_models/ckpt-1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(encoder=encoder,decoder=decoder,optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "ckpt_manager.save()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM041Vz/qIFxNaX0DOOV+5t",
   "collapsed_sections": [],
   "name": "training_GColab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
